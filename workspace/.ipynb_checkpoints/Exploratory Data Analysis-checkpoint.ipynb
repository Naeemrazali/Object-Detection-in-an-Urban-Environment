{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from glob import glob\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import math\n",
    "import IPython.display as display\n",
    "import glob\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "feature_descriptions = {\n",
    "    'image/height': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/width': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    'image/object/class/label': tf.io.VarLenFeature(tf.int64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_image_fn(example):\n",
    "    return tf.io.parse_single_example(example, feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_image(image_dataset):\n",
    "    for e in image_dataset:\n",
    "        image = Image.open(io.BytesIO(e['image/encoded'].numpy()))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_bbox(e):\n",
    "    xmins = e['image/object/bbox/xmin'].values.numpy()\n",
    "    ymins = e['image/object/bbox/ymin'].values.numpy()\n",
    "    xmaxs = e['image/object/bbox/xmax'].values.numpy()\n",
    "    ymaxs = e['image/object/bbox/ymax'].values.numpy()\n",
    "\n",
    "    for i, xmin in enumerate(xmins):\n",
    "        xmin = xmin * 640\n",
    "        xmin = xmin / 1920\n",
    "        xmins[i] = math.floor(xmin * 640)\n",
    "\n",
    "    for i, ymin in enumerate(ymins):\n",
    "        ymin = ymin * 640\n",
    "        ymin = ymin / 1080\n",
    "        ymins[i] = math.floor(ymin * 640 - 75)\n",
    "\n",
    "    for i, xmax in enumerate(xmaxs):\n",
    "        xmax = xmax * 640\n",
    "        xmax = xmax / 1920\n",
    "        xmaxs[i] = math.floor(xmax * 640)\n",
    "\n",
    "    for i, ymax in enumerate(ymaxs):\n",
    "        ymax = ymax * 640\n",
    "        ymax = ymax / 1080\n",
    "        ymaxs[i] = math.floor(ymax * 640 - 75)\n",
    "    return xmins, ymins, xmaxs, ymaxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_label(e):\n",
    "    labels = e['image/object/class/label'].values.numpy()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(ax, labels, xmins, ymins, xmaxs, ymaxs):\n",
    "    #something\n",
    "    colormap = {1: [1, 0, 0], 2: [0, 1, 0], 4: [0, 0, 1]}\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        xmin = xmins[i]\n",
    "        ymin = ymins[i]\n",
    "        xmax = xmaxs[i]\n",
    "        ymax = ymaxs[i]\n",
    "\n",
    "        rec = Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, facecolor='none', edgecolor=colormap[label])\n",
    "        ax.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_dataset):\n",
    "    f, ax = plt.subplots(2, 5, figsize=(20,20))\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    for e in image_dataset:\n",
    "        xmins, ymins, xmaxs, ymaxs = give_bbox(e)\n",
    "        labels = give_label(e)\n",
    "        img = Image.open(io.BytesIO(e['image/encoded'].numpy()))\n",
    "        ax[x, y].imshow(img)\n",
    "        draw_bbox(ax[x, y], labels, xmins, ymins, xmaxs, ymaxs)\n",
    "        ax[x, y].axis('off')\n",
    "\n",
    "        x = (x+1) % 2\n",
    "        y = (y+1) % 5\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1002334/826749534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#dataset = get_dataset(\"/app/project/Object-Detection-in-an-Urban-Environment/workspace/data/train/*.tfrecord\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfr_filepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/processed/*.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfr_filepaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_image_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "#dataset = get_dataset(\"/app/project/Object-Detection-in-an-Urban-Environment/workspace/data/train/*.tfrecord\")\n",
    "tfr_filepaths = glob(\"./data/processed/*.tfrecord\")\n",
    "dataset = tf.data.TFRecordDataset(tfr_filepaths)\n",
    "\n",
    "image_dataset = dataset.map(_parse_image_fn)\n",
    "\n",
    "image_dataset = image_dataset.shuffle(500)\n",
    "image_dataset = image_dataset.take(10)\n",
    "\n",
    "show_images(image_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(image_dataset):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    \"\"\"\n",
    "    f, ax = plt.subplots(2, 5, figsize=(20,20))\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    for e in image_dataset:\n",
    "        #xmins, ymins, xmaxs, ymaxs = give_bbox(e)\n",
    "        #labels = give_label(e)\n",
    "        img = Image.open(io.BytesIO(e['image/encoded'].numpy()))\n",
    "        ax[x, y].imshow(img)\n",
    "        #draw_bbox(ax[x, y], labels, xmins, ymins, xmaxs, ymaxs)\n",
    "        ax[x, y].axis('off')\n",
    "\n",
    "        #x = (x+1) % 2\n",
    "        #y = (y+1) % 5\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image/encoded'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_979463/3483497281.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_979463/2569834589.py\u001b[0m in \u001b[0;36mdisplay_instances\u001b[0;34m(image_dataset)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#xmins, ymins, xmaxs, ymaxs = give_bbox(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#labels = give_label(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image/encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#draw_bbox(ax[x, y], labels, xmins, ymins, xmaxs, ymaxs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image/encoded'"
     ]
    }
   ],
   "source": [
    "display_instances(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STUDENT SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
